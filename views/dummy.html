<html>
	<head>
		<title>Lychee Labs</title>
		<link rel="stylesheet" href="/css/style.css" type="text/css">
	</head>
	<body>
		<div id="red">
			<div style="width: 530px;height: 50px; margin: auto;padding-top: 5px;">
				<font id="title">
					lycheelabs&nbsp;&nbsp;&nbsp;

				</font>
				<div id="navigation">
					about&nbsp;&nbsp;

				</div>
				<div id="navigation">
					store&nbsp;&nbsp;
		
				</div>
				<div id="navigation">
					projects&nbsp;&nbsp;

				</div>
				<div id="navigation">
					contact&nbsp;&nbsp;

				</div>
			</div>
		</div>
		<div id="content">
			<div id="slideshow" style="background-image:url('/img/slide1.jpg');">
				<div id="slidetitle">
					<h1>DUMMY</h1>
					<h2>Robotic Desk Cleaner</h2>
					<h3> EE125 Final Project </h3>
				</div>
			</div>
			<div class="text">
				<h2 class="intext"> "If a cluttered desk is a sign of a cluttered mind..." </h2>
				<div class="text18">
					Of what then, is an empty desk a sign? Some would say an empty mind, but we think an empty desk means there's finally some free space to work on!<br><br>
					Instead of actually cleaning our desks, we built Dummy - a robotic arm that clears your desk of clutter to save time and space.
					
					Built by: Nelson Zhang, Siddhartho Bhattacharya, Anibal Madrid.
					
					Dummy is comprised of a 6-joint arm and a single webcam. The full list of parts is as follows:<br><br>
					&nbsp;- (6) Dynamixel AX-12 servos + servo brackets/connectors<br>
					&nbsp;- (1) USB2Dynamixel serial/TTL converter<br>
					&nbsp;- (1) RoadNarrows Graboid Series D gripper<br>
					&nbsp;- (1) 12V Power supply or battery<br>
					&nbsp;- (1) HD Webcam<br>
					&nbsp;- (3) Party cups<br>
					&nbsp;- (1) plastic knife<br>
					&nbsp;- Counterweights (for the robot base)<br>
					<br>
					
					Code was written purely in Python, using the SimpleCV library for computer vision and pyDynamixel to communicate with the
					servos. In addition to the CV and inverse kinematics code, we also wrote some very simple Logo-like syntax to easily 
					pose Dummy in any configuration, and a classifier for objects that Dummy sees.
					
					Dummy is capable of detecting any number of objects within its workspace and calculate their approximate dimensions. 
					It then maneuvers to grasp each object, carry it over to a bin, and drop it.
					Repeating this process (trying again if it ever drops something), Dummy eventually cleans the entire desk.
				</div>
					
				video
					
				<h2> Design </h2>
				<div class="text18">
					The major challenges in building Dummy were the computer vision and inverse kinematics involved in finding and grasping objects.
					Hence, we carefully designed the robot to reduce these hard problems into easier subproblems. Namely:<br>
					&nbsp;- The camera is positioned to capture the entire workspace, including the robot and target bin<br>
					&nbsp;- The wrist joint is only moved along a plane parallel to the desk<br>
					&nbsp;- The kinematics of the 6 joints are split into 3 subproblems:<br>
					&nbsp;&nbsp;1. Alignment of the arm with the object<br>
					&nbsp;&nbsp;2. Alignment of the grasper with the object's minor axis<br>
					&nbsp;&nbsp;3. Extending the arm to the correct distance<br>
					<br>
					The 3 subproblems have closed-form geometric solutions, making the inverse kinematics much easier to implement. Subproblem 2 is
					made possible by our design of the wrist joint, which offers 4 degrees freedom for the gripper. This allows Dummy to grasp objects
					in the most stable manner (i.e. along the minor axis of the bounding rectangle/ellipse).<br>
				</div>
				
				<h2> Mathematics for Dummies </h2>
				<div class="text18">
					We used several techniques from EE125 in Dummy's design. <br>
					To move from pixel to real world coordinates, we applied the inverse homography matrix computed from the 4 corners of the workspace
					(in pixel coordinates) and the real world dimensions of the workspace.<br>
					Applying a median filter to the background subtracted image of the table reduced noise and made blob detection more accurate.<br><br>
					The Kaden-Pahan subproblems allowed us to easily break down and derive geometric solutions for the inverse kinematics of our 6-joint arm.
					<br>
					<img src="/img/ik.png"><br>
					Pictured above: The 3 subproblems/solutions that we used to construct a solution to the entire inverse kinematics problem.<br>
					</div>
				
				<h2> Computer Vision </h2>
				<div class="text18">
					The first step is to determine what the clean workspace is, thus forming a background image from which we will compare other images to during our background subtraction. This was done by simply taking a picture of the clean workspace and saving it. Then, the user is prompted to mark 4 corners in that image signifying the corners of our workspace to produce our image homography and resulting mapping from image coordinates to real world coordinates. The real world dimensions of the workspace must be measured and input beforehand.
					<br><br>
					<img src="/img/1.png"><br>
					With the homography calculated and the background set, we begin our main loop in our program by always setting the robot arm in the initial configuration, and then taking an image. We find the differences of the image from the background through image subtraction in order to make it easy to identify objects which must be moved and sorted. The subtracted image is also median filtered and binarized to reduce noise and make object detection even simpler.
					<br><br>
					The resulting image is passed into a Image.findBlobs() function using the simpleCV library, which attempts to find bounded hulls in an image that have a bounded area greater than a certain threshold so that patches of noise are not detected as objects. The location of each object is found via its mass-based centroid done by the Blob.centroid() function call in simpleCV. That coordinate is translated to our real world coordinate system using our inverse homography, and can be passed into our inverse kinematics program when we need to move the arm to pick up the object. 
					<br><br>
					<img src="/img/2.png">
					<img src="/img/3.png"><br>
					Once the object is found, we find its minimum bounding rectangle and angle from the horizontal, both of which are function calls to the simpleCV library - Blob.minRect() and Blob.angle() respectively. The angle is particularly important so that we can tell our robotic arm at what angle the grasper should be oriented to pick up the object along the axis which ensures a stable grip. Finally, we also store the ratio of the length to the height of the object in an effort to gain some information about the thickness/shape of the object, which can be used for rudimentary object classification. Thus pencils and other long, thin objects would be quickly identified with a high ratio of length to width while erasers or round objects would have a ratio closer to 1 and would be identified as such.
					<br><br>
					With all this information for each object, we simply pass the list of identified objects into the next phase of our program which does the inverse kinematics for each object, moving the arm to that object, grasping it, moving it to the corresponding bin, and releasing it. This is repeated in our program until all objects have been cleared and sorted.
					<br><br>
				</div>
				
				<h2> Future improvements </h2>
				<div class="text18">
					One major issue we ran into while building Dummy was the insufficient torque compensation on the AX-12 servos. After several
					failures due to overheating, we were forced to reduce the link length on the robot arm and hence also reduce the effect workspace
					reachable by Dummy.<br>
					However, the servos were quite accurate, so we did not run into any problems with drift in angles. Open-loop feedback would still be
					a good idea to implement, though, by checking the end effector position (using forward kinematics) with the planned position.<br>
					Finally, the gripper was very good at grasping long objects, but objects with less regular shapes are dropped more often. Using a
					universal gripper in place of the 2-finger gripper would solve this problem.<br><br>
				</div>
				
			</div>
		</div>
	</body>
</html>
